# Основные алгоритмы сортировки

## 1. Bubble Sort (Пузырьковая сортировка)

Bubble Sort — один из самых простых алгоритмов сортировки. Принцип работы заключается в многократном проходе по массиву и последовательном сравнении соседних элементов. Если соседние элементы стоят в неправильном порядке, они меняются местами. Проходы повторяются до тех пор, пока массив полностью не отсортирован.

Алгоритм стабилен (не меняет порядок равных элементов) и прост для реализации, но крайне неэффективен на больших данных. В худшем и среднем случае его сложность — O(n²), а в лучшем случае, когда массив уже отсортирован, O(n). Память используется минимальная — O(1), так как сортировка проводится на месте.

Bubble Sort хорошо подходит для небольших массивов или когда нужно быстро реализовать учебный пример сортировки. В Java его обычно используют только в учебных целях или для массивов размером до десятков элементов.

**Пример в Java:**

```java
for (int i = 0; i < arr.length - 1; i++) {
    for (int j = 0; j < arr.length - i - 1; j++) {
        if (arr[j] > arr[j + 1]) {
            int temp = arr[j];
            arr[j] = arr[j + 1];
            arr[j + 1] = temp;
        }
    }
}
```

---

## 2. Selection Sort (Сортировка выбором)

Selection Sort работает по принципу выбора наименьшего (или наибольшего) элемента на каждом шаге и его перемещения в начало массива. Проходы повторяются, пока все элементы не будут упорядочены.

Алгоритм имеет сложность O(n²) в худшем, среднем и лучшем случаях и использует O(1) памяти, так как сортировка проводится на месте. Он не является стабильным, так как равные элементы могут менять свой порядок при перемещении.

Selection Sort удобен для массивов, где важен минимальный расход памяти, но не критична скорость. В Java этот метод редко используют в реальных проектах из-за низкой производительности на больших данных.

**Пример в Java:**

```java
for (int i = 0; i < arr.length - 1; i++) {
    int minIndex = i;
    for (int j = i + 1; j < arr.length; j++) {
        if (arr[j] < arr[minIndex]) {
            minIndex = j;
        }
    }
    int temp = arr[minIndex];
    arr[minIndex] = arr[i];
    arr[i] = temp;
}
```

---

## 3. Insertion Sort (Сортировка вставками)

Insertion Sort строит отсортированную последовательность по одному элементу. На каждом шаге берётся следующий элемент из массива и вставляется в правильную позицию в уже отсортированной части.

Алгоритм стабилен и эффективен для почти отсортированных массивов. В худшем и среднем случаях сложность O(n²), в лучшем — O(n) для уже почти отсортированных данных. Память используется минимальная — O(1).

Insertion Sort идеален для небольших массивов или массивов с частично отсортированными данными. В Java часто используют этот алгоритм в комбинации с другими сортировками для малых подмассивов в `Arrays.sort()` для оптимизации.

**Пример в Java:**

```java
for (int i = 1; i < arr.length; i++) {
    int key = arr[i];
    int j = i - 1;
    while (j >= 0 && arr[j] > key) {
        arr[j + 1] = arr[j];
        j--;
    }
    arr[j + 1] = key;
}
```

---

## 4. Merge Sort (Сортировка слиянием)

Merge Sort — это алгоритм «разделяй и властвуй». Массив рекурсивно делится на две половины до тех пор, пока не останется массивы из одного элемента. Затем они объединяются в отсортированные последовательности с помощью процедуры слияния.

Сложность алгоритма стабильна — O(n log n) в любом случае. Память используется дополнительная — O(n), так как нужен временный массив для слияния. Алгоритм стабилен и хорошо масштабируется на больших данных.

Merge Sort часто применяют, когда требуется стабильная сортировка или сортировка больших массивов. В Java его используют внутри `Collections.sort()` для объектов, чтобы гарантировать стабильность сортировки.

**Пример в Java:**

```java
void mergeSort(int[] arr) {
    if (arr.length < 2) return;
    int mid = arr.length / 2;
    int[] left = Arrays.copyOfRange(arr, 0, mid);
    int[] right = Arrays.copyOfRange(arr, mid, arr.length);
    mergeSort(left);
    mergeSort(right);
    merge(arr, left, right);
}
void merge(int[] arr, int[] left, int[] right) {
    int i = 0, j = 0, k = 0;
    while (i < left.length && j < right.length) {
        if (left[i] <= right[j]) arr[k++] = left[i++];
        else arr[k++] = right[j++];
    }
    while (i < left.length) arr[k++] = left[i++];
    while (j < right.length) arr[k++] = right[j++];
}
```

---

## 5. Quick Sort (Быстрая сортировка)

Quick Sort также использует стратегию «разделяй и властвуй». Выбирается опорный элемент (pivot), после чего массив делится на две части: элементы меньше pivot и больше pivot. Затем рекурсивно сортируются обе части.

Средняя сложность алгоритма — O(n log n), худшая — O(n²) (редко, при неудачном выборе опорного элемента). Память — O(log n) для рекурсивного стека. Алгоритм не является стабильным, но в среднем работает очень быстро.

Quick Sort подходит для сортировки больших массивов с большим объёмом данных. В Java `Arrays.sort()` для примитивных типов использует модифицированную версию Quick Sort с оптимизацией для малых массивов и медианой из трёх элементов.

**Пример в Java:**

```java
void quickSort(int[] arr, int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
int partition(int[] arr, int low, int high) {
    int pivot = arr[high];
    int i = low - 1;
    for (int j = low; j < high; j++) {
        if (arr[j] <= pivot) {
            i++;
            int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;
        }
    }
    int temp = arr[i + 1]; arr[i + 1] = arr[high]; arr[high] = temp;
    return i + 1;
}
```

---

## 6. Heap Sort (Сортировка кучей)

Heap Sort строит из массива бинарную кучу (max-heap) и затем последовательно извлекает максимальный элемент, помещая его в конец массива.

Сложность алгоритма — O(n log n) в худшем, среднем и лучшем случаях. Память — O(1), так как сортировка выполняется на месте. Алгоритм не является стабильным.

Heap Sort хорошо подходит для массивов большого размера, когда важна гарантированная временная сложность. В Java реализовать можно через `PriorityQueue`, хотя встроенные методы сортировки обычно используют Quick Sort или Merge Sort для оптимизации.

**Пример в Java:**

```java
void heapSort(int[] arr) {
    int n = arr.length;
    for (int i = n / 2 - 1; i >= 0; i--) heapify(arr, n, i);
    for (int i = n - 1; i >= 0; i--) {
        int temp = arr[0]; arr[0] = arr[i]; arr[i] = temp;
        heapify(arr, i, 0);
    }
}
void heapify(int[] arr, int n, int i) {
    int largest = i, l = 2*i+1, r = 2*i+2;
    if (l < n && arr[l] > arr[largest]) largest = l;
    if (r < n && arr[r] > arr[largest]) largest = r;
    if (largest != i) {
        int swap = arr[i]; arr[i] = arr[largest]; arr[largest] = swap;
        heapify(arr, n, largest);
    }
}
```

---

## Сравнительная таблица сортировок

| Алгоритм       | Сложность (Лучший) | Сложность (Средний) | Сложность (Худший) | Память   | Стабильность | Применение в Java                                                                   |
| -------------- | ------------------ | ------------------- | ------------------ | -------- | ------------ | ----------------------------------------------------------------------------------- |
| Bubble Sort    | O(n)               | O(n²)               | O(n²)              | O(1)     | Да           | Учебные задачи, маленькие массивы                                                   |
| Selection Sort | O(n²)              | O(n²)               | O(n²)              | O(1)     | Нет          | Минимальная память, учебные задачи                                                  |
| Insertion Sort | O(n)               | O(n²)               | O(n²)              | O(1)     | Да           | Малые или почти отсортированные массивы, внутри Arrays.sort() для малых подмассивов |
| Merge Sort     | O(n log n)         | O(n log n)          | O(n log n)         | O(n)     | Да           | Collections.sort() для объектов, стабильная сортировка                              |
| Quick Sort     | O(n log n)         | O(n log n)          | O(n²)              | O(log n) | Нет          | Arrays.sort() для примитивов, быстрая сортировка больших массивов                   |
| Heap Sort      | O(n log n)         | O(n log n)          | O(n log n)         | O(1)     | Нет          | Массивы больших размеров, гарантированная временная сложность                       |

### 1. Стек (Stack)

Стек — это структура данных, которая работает по принципу **LIFO** (Last In, First Out — последний вошёл, первый вышел). Это значит, что элементы добавляются и удаляются только с одного конца, называемого **верхом стека**. Стек часто используется в задачах, где нужно сохранить порядок операций или реализовать откат действий, например, в браузере (история страниц) или при вычислении выражений.

Реализация стека может быть как на массиве, так и на связанном списке. В случае массива операции push (добавление) и pop (удаление) выполняются за O(1), если не нужно расширять массив. На связанном списке добавление и удаление тоже выполняются за O(1), что делает стек очень эффективным для динамических данных.

Стек активно применяется в алгоритмах обхода графов и деревьев (DFS), в реализации рекурсий и в некоторых алгоритмах компиляции. Также используется в парсерах, где нужно проверять корректность скобочных выражений.

Недостатком стека является ограничение на доступ к элементам — получить элемент посередине напрямую нельзя, только последовательное извлечение с верха. Это делает стек узкоспециализированной структурой данных, но крайне полезной там, где порядок операций важнее доступа к любому элементу.

---

### 2. Очередь (Queue)

Очередь — это структура данных, которая работает по принципу **FIFO** (First In, First Out — первый вошёл, первый вышел). Элементы добавляются в конец очереди (tail) и извлекаются с начала (head). Очереди часто применяются в системах управления задачами, потоках данных и моделировании процессов, где важен порядок обработки.

Очереди можно реализовать с помощью массивов, связанных списков или кольцевых буферов. В массивной реализации операции enqueue и dequeue могут быть O(1) при правильной организации кольцевого буфера. Связанный список позволяет динамически изменять размер очереди без пересоздания массива.

Существуют также разновидности очередей: **дек (двусторонняя очередь)** позволяет вставлять и удалять элементы с обоих концов, а **приоритетная очередь** упорядочивает элементы по приоритету, что делает ее важной в алгоритмах сортировки и планировании задач.

Недостаток обычной очереди в том, что доступ к произвольному элементу тоже ограничен — только через последовательное извлечение. Для работы с элементами по приоритету лучше использовать приоритетные очереди, которые обычно реализуются через кучу (heap).

---

### 3. Графы (Graphs)

Граф — это структура данных, состоящая из **вершин (узлов)** и **рёбер**, соединяющих их. Графы могут быть направленными или ненаправленными, взвешенными или невзвешенными. Они позволяют моделировать сложные сети, такие как социальные сети, транспортные маршруты и компьютерные сети.

Графы обычно представляют с помощью **списка смежности** или **матрицы смежности**. Список смежности экономит память для разреженных графов и позволяет эффективно перебирать соседей. Матрица смежности удобна для плотных графов и быстрого доступа к наличию ребра, но требует O(V²) памяти, где V — количество вершин.

Алгоритмы на графах включают поиск в глубину (DFS), поиск в ширину (BFS), алгоритмы поиска кратчайшего пути (Dijkstra, Bellman-Ford) и алгоритмы для минимального остовного дерева (Kruskal, Prim). Графы являются основой для многих сложных алгоритмических задач.

Основной недостаток графов — сложность реализации и потребность в большом объёме памяти для плотных графов. Также операции поиска и модификации могут быть затратными, особенно если граф большой.

---

### 4. Деревья (Trees)

Дерево — это структура данных, состоящая из **узлов**, где один узел является корнем, а все остальные имеют родителя и могут иметь потомков. Деревья эффективно моделируют иерархические структуры, такие как файловые системы или организации.

Бинарное дерево — популярный тип, где каждый узел имеет максимум двух потомков. Бинарные деревья поиска (BST) позволяют быстро искать, добавлять и удалять элементы. В среднем операции поиска, вставки и удаления выполняются за O(log n), но в худшем случае (несбалансированное дерево) могут деградировать до O(n).

Деревья также применяются в алгоритмах обхода (in-order, pre-order, post-order), в реализации выражений, компиляции, базах данных и индексах. Балансировка дерева, например, с помощью AVL или красно-чёрного дерева, гарантирует, что операции останутся эффективными даже в худших случаях.

Недостаток деревьев в том, что без балансировки они могут стать "выражением в линию", что ухудшает эффективность. Поэтому для больших динамических структур данных чаще используют сбалансированные деревья.

---

### 5. Красно-чёрные деревья (Red-Black Trees)

Красно-чёрное дерево — это **самобалансирующееся бинарное дерево поиска**, где каждый узел имеет цвет (красный или черный) и соблюдаются правила для балансировки. Оно гарантирует, что глубина дерева всегда O(log n), что обеспечивает эффективный поиск, вставку и удаление.

Правила включают: корень всегда черный, красные узлы не могут быть соседними, все пути от корня до листьев имеют одинаковое количество черных узлов. Эти ограничения обеспечивают "почти сбалансированное" дерево и предотвращают деградацию в длинную цепочку.

Красно-чёрные деревья применяются в Java в структуре **TreeMap** и **TreeSet**, обеспечивая упорядоченное хранение и быстрый доступ к элементам. Они оптимальны для частых вставок и удалений, где важно поддерживать упорядоченность данных.

Недостаток — высокая сложность реализации и необходимость поддержки правил балансировки при каждой модификации дерева. Но для больших наборов данных с частыми операциями это гораздо эффективнее, чем обычные бинарные деревья поиска.

---

### 6. Куча (Heap)

Куча — это структура данных, обычно **бинарная куча**, которая поддерживает **свойство кучи**: каждый родительский узел больше или меньше своих детей (max-heap или min-heap). Она широко используется для реализации приоритетных очередей и алгоритмов сортировки (HeapSort).

Вставка и извлечение элемента с вершины выполняются за O(log n), что делает кучу очень эффективной для динамических множеств с быстрым доступом к минимуму или максимуму. Куча реализуется обычно в виде массива, где дочерние элементы вычисляются по индексам.

Кучи применяются в планировании задач, потоках с приоритетами, алгоритмах на графах (Dijkstra) и сортировках. Max-heap и min-heap позволяют быстро находить экстремальные значения без полного обхода структуры.

Недостаток — прямой доступ к произвольному элементу медленный (O(n)), так как структура оптимизирована только для доступа к вершине. Для произвольного поиска лучше использовать хэш-таблицы или сбалансированные деревья.

---

### Сравнительная таблица по Big O (Java)

| Структура данных               | Доступ   | Поиск    | Вставка               | Удаление             |
| ------------------------------ | -------- | -------- | --------------------- | -------------------- |
| Массив (Array)                 | O(1)     | O(n)     | O(n)                  | O(n)                 |
| Стек (Stack)                   | O(n)     | O(n)     | O(1)                  | O(1)                 |
| Очередь (Queue)                | O(n)     | O(n)     | O(1)                  | O(1)                 |
| Связанный список (Linked List) | O(n)     | O(n)     | O(1) (в начале/конце) | O(1) (узел известен) |
| Граф (Adjacency List)          | O(V+E)   | O(V+E)   | O(1)                  | O(E)                 |
| Дерево (Binary Search Tree)    | O(log n) | O(log n) | O(log n)              | O(log n)             |
| Красно-чёрное дерево           | O(log n) | O(log n) | O(log n)              | O(log n)             |
| Хэш-таблица (HashMap)          | O(1)     | O(1)     | O(1)                  | O(1)                 |

### Двоичное дерево поиска (Binary Search Tree, BST)

Двоичное дерево поиска (BST) — это вид бинарного дерева, где каждый узел имеет максимум двух потомков: левый и правый. Главное свойство BST заключается в том, что для любого узла все элементы в левом поддереве меньше текущего узла, а все элементы в правом поддереве — больше или равны. Это позволяет быстро искать элементы и поддерживать упорядоченность данных.

Операции поиска, вставки и удаления в среднем выполняются за O(log n), где n — количество элементов в дереве. Однако в худшем случае, если дерево несбалансировано и вырождается в цепочку, сложность может достигать O(n). Поэтому для больших данных часто применяют сбалансированные версии дерева, такие как AVL или красно-чёрные деревья.

BST активно используется для реализации множеств, словарей и индексирования данных в базах данных. Обход дерева может выполняться разными способами: in-order (возвращает элементы в отсортированном порядке), pre-order, post-order. Эти обходы необходимы для поиска, сортировки и копирования дерева.

Недостатком BST является потенциальная потеря эффективности при несбалансированном дереве, что делает необходимой балансировку. Несмотря на это, BST остаётся одной из самых важных структур данных для организации упорядоченной информации.

---

### Основные операции и их сложности (Big O)

| Операция         | Среднее  | Худшее |
| ---------------- | -------- | ------ |
| Поиск            | O(log n) | O(n)   |
| Вставка          | O(log n) | O(n)   |
| Удаление         | O(log n) | O(n)   |
| Минимум/Максимум | O(log n) | O(n)   |


